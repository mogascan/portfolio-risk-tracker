"""
AI analysis API endpoints
"""
from fastapi import APIRouter, Query, HTTPException, Depends, Path, Body
from typing import List, Optional, Dict, Any
import os
import json
import logging
import random
from datetime import datetime, timedelta
import uuid

from app.models.ai import (
    MarketPrediction, SentimentAnalysis, MarketInsight, 
    PortfolioRecommendation, AIAnalysisRequest
)
from app.core.logging import get_logger
from app.services.ai import AIService
from app.services.ai.openai_service import OpenAIService
from app.services.ai.intent_classifier import IntentClassifier, IntentType
from app.services.ai.prompt_templates import get_prompt_for_intent
from app.services.ai.context_registry import ContextRegistry, ContextPriority
from app.services.news import crypto_news_service, macro_news_service, reddit_service

# Initialize logger
logger = get_logger(__name__)

# Create router
router = APIRouter(prefix="/ai", tags=["AI Analysis"])

# Initialize AI services
ai_service = AIService()
openai_service = OpenAIService()

# Initialize intent classifier and context registry
intent_classifier = IntentClassifier()
context_registry = ContextRegistry()

# Fetch news data to include in AI context
def get_news_context(query: str = None, limit: int = 5):
    """
    Get recent news from various sources to provide context to AI
    
    Args:
        query: Optional query term to filter news
        limit: Maximum number of items to include per category
        
    Returns:
        Dictionary containing news data from different sources
    """
    try:
        logger.info(f"Fetching news context for AI with query: {query}, limit: {limit}")
        
        # Get crypto news
        crypto_data = []
        try:
            if query:
                # Try to get news related to the query
                crypto_data = crypto_news_service.get_news(limit=limit, filter_term=query)
            else:
                # Get general crypto news
                crypto_data = crypto_news_service.get_news(limit=limit)
            
            logger.info(f"Successfully fetched {len(crypto_data)} crypto news items")
        except Exception as e:
            logger.error(f"Error fetching crypto news for context: {e}")
            
        # Retrieve macro news for different categories
        macro_data = {}
        try:
            # Get different categories of macro news
            categories = ["business", "technology", "economy", "markets", "policy"]
            
            for category in categories:
                try:
                    category_news = macro_news_service.get_news(category=category, limit=limit)
                    if category_news:
                        macro_data[category] = category_news
                        logger.info(f"Successfully fetched {len(category_news)} {category} news items")
                except Exception as category_error:
                    logger.error(f"Error fetching {category} news: {category_error}")
        except Exception as e:
            logger.error(f"Error fetching macro news for context: {e}")
            
        # Get Reddit posts
        reddit_data = []
        try:
            # Try to get posts from cryptocurrency subreddit
            reddit_data = reddit_service.get_posts(subreddit="cryptocurrency", sort="hot", limit=limit)
            logger.info(f"Successfully fetched {len(reddit_data)} Reddit posts")
        except Exception as e:
            logger.error(f"Error fetching Reddit posts for context: {e}")
            
        # Return all news data
        return {
            "crypto": crypto_data,
            "macro": macro_data,
            "reddit": reddit_data
        }
    except Exception as e:
        logger.error(f"Error building news context: {e}")
        return {"crypto": [], "macro": {}, "reddit": []}

@router.post("/chat")
async def chat(request: dict):
    """
    Process a chat message and return AI response with market insights
    """
    try:
        # Extract various components from the request
        message = request.get("message", "")
        model = request.get("model", "gpt-4-turbo-preview")
        context_from_request = request.get("context", {})
        
        # Log the inputs for debugging
        logger.info(f"Chat request: model={model}, message length={len(message)}")
        logger.info(f"Context included in request: {bool(context_from_request)}")
        
        # Classify the user's intent to determine which context providers to use
        intent_type, confidence = intent_classifier.classify(message)
        logger.info(f"Classified intent: {intent_type.name} with confidence {confidence:.2f}")
        
        # In Phase 1, we'll use the context from the request instead of fetching from providers
        # This will be replaced in Phase 2 with context providers
        combined_context = {}
        
        # Add the request context to our context collection
        if context_from_request:
            combined_context.update(context_from_request)
            
        # Add metadata about the intent classification
        combined_context["_intent"] = {
            "type": intent_type.name,
            "confidence": confidence
        }
        
        # Get the appropriate prompt template for this intent
        system_prompt = get_prompt_for_intent(intent_type)
        
        # Special handling for price queries (temporary, will be replaced in Phase 2)
        message_lower = message.lower()
        is_crypto_price_query = intent_type == IntentType.MARKET_PRICE
        
        # If this is a crypto price query, check if we have the requested coin
        if is_crypto_price_query:
            # List of available coins in our dataset (from market_data.json)
            available_coins = []
            if context_from_request and isinstance(context_from_request, dict) and "market" in context_from_request:
                market_data = context_from_request["market"]
                if isinstance(market_data, dict) and "coins" in market_data:
                    available_coins = [
                        {'symbol': coin.get('symbol', '').lower(), 'name': coin.get('name', '').lower()} 
                        for coin in market_data["coins"]
                    ]
            
            # Map of common cryptocurrency queries to check against 
            crypto_keywords = {
                "bitcoin": ["bitcoin", "btc"],
                "ethereum": ["ethereum", "eth"],
                "solana": ["solana", "sol"],
                "avalanche": ["avalanche", "avax"],
                "euler": ["euler", "eul"],
                "pepe": ["pepe"],
                "dogecoin": ["dogecoin", "doge"],
                "shiba": ["shiba", "shib"],
                "polkadot": ["polkadot", "dot"],
                "cardano": ["cardano", "ada"],
                "ripple": ["ripple", "xrp"],
                "binance": ["binance", "bnb"],
                "tether": ["tether", "usdt"],
                "usdc": ["usdc"],
                "dai": ["dai"]
            }
            
            # Check which crypto the user is asking about
            requested_crypto = None
            for crypto, terms in crypto_keywords.items():
                if any(term in message_lower for term in terms):
                    requested_crypto = crypto
                    break
            
            logger.info(f"User is asking about cryptocurrency: {requested_crypto}")
            
            # Check if the requested crypto is available in our data
            is_available = False
            if requested_crypto and available_coins:
                is_available = any(
                    any(term in coin['symbol'] or term in coin['name'] 
                        for term in crypto_keywords.get(requested_crypto, []))
                    for coin in available_coins
                )
            
            logger.info(f"Requested crypto '{requested_crypto}' is available: {is_available}")
            
            # If not available, generate a message explaining our limited data
            if requested_crypto and not is_available:
                # Get a list of available cryptocurrencies to show the user
                available_names = []
                if market_data and isinstance(market_data, dict) and "coins" in market_data:
                    available_names = [coin.get('name') for coin in market_data["coins"] if coin.get('name')]
                
                available_list = ", ".join(available_names) if available_names else "none"
            
            return {
                "message": (
                    f"I'm sorry, but I don't have data for {requested_crypto.title()} in my current dataset. "
                    f"While I aim to cover the top 500 cryptocurrencies, my test dataset currently only includes: {available_list}. "
                    "Please ask about one of these cryptocurrencies instead."
                ),
                "status": "success"
            }
        
        # Prepare message for the AI
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": message}
        ]

        # Log what we're sending to the AI
        logger.info(f"Using intent-specific prompt for {intent_type.name}")
        logger.info(f"Sending {len(messages)} messages to AI with {len(combined_context)} context elements")
        
        # Process the request with OpenAI
        response = await openai_service.process_with_context(
            messages=messages,
            context=combined_context,
            model=model
        )
        
        return {
            "message": response,
            "status": "success",
            "intent": intent_type.name,
            "confidence": float(confidence)
        }
    
    except Exception as e:
        logger.error(f"Error in chat endpoint: {str(e)}", exc_info=True)
        return {
            "message": f"I'm sorry, but I encountered an error processing your request: {str(e)}",
            "status": "error"
        }

def parse_query_for_market_data(message, market_data, portfolio):
    """
    Parse query to detect requests for market data and add the relevant data to the context
    """
    logger.info("Parsing query for market data")
    
    message_lower = message.lower()
    response = ""
    
    # Check for portfolio-related queries
    portfolio_related_terms = [
        "portfolio value", "portfolio worth", "my portfolio", 
        "my holdings", "my coins", "my crypto", "my assets",
        "what's the value", "value of the portfolio", "value of my portfolio"
    ]
    
    is_portfolio_query = any(term in message_lower for term in portfolio_related_terms)
    
    # Handle portfolio data specifically for portfolio-related queries
    if is_portfolio_query:
        logger.info("Detected portfolio-related query")
        
        if portfolio and isinstance(portfolio, dict):
            has_portfolio_data = portfolio.get('hasData', False) or (
                portfolio.get('assets') and len(portfolio.get('assets', [])) > 0
            )
            
            if has_portfolio_data:
                # Portfolio data is available, add it to the response
                response += "\nPORTFOLIO DATA:\n"
                response += f"Total Portfolio Value: ${portfolio.get('totalValue', 0):,.2f}\n"
                response += f"Total Cost Basis: ${portfolio.get('totalCost', 0):,.2f}\n"
                response += f"Total Profit/Loss: ${portfolio.get('absoluteProfit', 0):,.2f}\n"
                
                if portfolio.get('assets'):
                    response += "\nHoldings:\n"
                    for asset in portfolio.get('assets', []):
                        response += f"- {asset.get('name', 'Unknown')} ({asset.get('symbol', 'Unknown')}): "
                        response += f"{asset.get('amount', 0)} tokens, "
                        response += f"value: ${asset.get('value', 0):,.2f}\n"
                
                logger.info("Added portfolio data to response")
            else:
                # No portfolio data available
                response += "\nPORTFOLIO DATA:\n"
                response += "No portfolio data is available. Please add assets to your portfolio first.\n"
                response += "You can add assets by going to the Portfolio section and clicking 'Add Asset'.\n"
                logger.info("No portfolio data available for this query")
    
    # Extract query terms for potential coin names
    query_terms = message_lower.split()
    logger.info(f"Initial query terms: {query_terms}")
    
    # Special handling for popular meme coins and tokens that might be missed
    meme_coins_map = {
        "pepe": ["pepe", "pepecoin"],
        "doge": ["dogecoin", "doge"],
        "shib": ["shiba", "shiba inu", "shibainu"]
    }
    
    # Check if any meme coins are mentioned in the message
    for coin, variants in meme_coins_map.items():
        if coin in message_lower or any(variant in message_lower for variant in variants):
            if coin not in query_terms:
                query_terms.append(coin)
                logger.info(f"Added meme coin term: {coin}")
    
    # If we have market data to work with
    if market_data and isinstance(market_data, dict) and "coins" in market_data:
        all_coins = market_data["coins"]
        logger.info(f"Market data contains {len(all_coins)} coins")
        
        # Extract key terms that might be coin names or symbols
        # Skip common words that aren't likely to be coin names
        common_words = ["price", "of", "the", "is", "what", "how", "much", "worth", "cost", 
                        "value", "market", "cap", "about", "tell", "me", "current"]
        coin_query_terms = [term for term in query_terms if len(term) >= 2 and term not in common_words]
        logger.info(f"Filtered coin query terms: {coin_query_terms}")
        
        # Directly search for coins by exact name/symbol match first
        matches = []
        
        # First pass: look for exact matches on symbol or name
        for coin in all_coins:
            coin_symbol = coin.get('symbol', '').lower()
            coin_name = coin.get('name', '').lower()
            coin_id = coin.get('id', '').lower()
            
            for term in coin_query_terms:
                term_lower = term.lower()
                # Check for exact matches
                if (term_lower == coin_symbol or 
                    term_lower == coin_name or 
                    term_lower == coin_id):
                    # Add exact matches to the front of the list
                    matches.insert(0, {'coin': coin, 'match_type': 'exact', 'term': term_lower})
                    logger.info(f"Found exact match: {term} -> {coin.get('name')} ({coin.get('symbol')})")
                    
                # Special handling for PEPE and other meme coins - more aggressive matching
                elif term_lower in ["pepe", "pepecoin"] and ("pepe" in coin_symbol or "pepe" in coin_name):
                    matches.insert(0, {'coin': coin, 'match_type': 'exact', 'term': term_lower})
                    logger.info(f"Found special PEPE match: {term} -> {coin.get('name')} ({coin.get('symbol')})")
        
        # Second pass: If no exact matches, try partial matches
        if not matches:
            for coin in all_coins:
                coin_symbol = coin.get('symbol', '').lower()
                coin_name = coin.get('name', '').lower()
                coin_id = coin.get('id', '').lower()
                
                for term in coin_query_terms:
                    term_lower = term.lower()
                    # Check for partial matches
                    if (term_lower in coin_symbol or
                        term_lower in coin_name or
                        term_lower in coin_id or
                        # Add more aggressive matching for common terms
                        (term_lower in ["pepe"] and ("pepe" in coin_symbol or "pepe" in coin_name)) or
                        (term_lower in ["doge"] and ("doge" in coin_symbol or "dog" in coin_name)) or
                        (term_lower in ["shib"] and ("shib" in coin_symbol or "shib" in coin_name))):
                        matches.append({'coin': coin, 'match_type': 'partial', 'term': term_lower})
                        logger.info(f"Found partial match: {term} -> {coin.get('name')} ({coin.get('symbol')})")

        # Add matched coin data to the response
        if matches:
            logger.info(f"Found {len(matches)} matches for query terms")
            
            # Group matches by match type
            exact_matches = [m for m in matches if m['match_type'] == 'exact']
            partial_matches = [m for m in matches if m['match_type'] == 'partial']
            
            # Use exact matches if available, otherwise use partial matches
            used_matches = exact_matches if exact_matches else partial_matches
            
            # Special debug for PEPE coin
            pepe_matches = [m for m in used_matches if "pepe" in m['coin'].get('name', '').lower() or "pepe" in m['coin'].get('symbol', '').lower()]
            if "pepe" in message_lower and pepe_matches:
                logger.info(f"PEPE matches found: {pepe_matches}")
            elif "pepe" in message_lower:
                logger.warning(f"User asked about PEPE but no matches found in market data")
                # Search all coins directly to confirm if PEPE is in the dataset
                pepe_coins = [c for c in all_coins if "pepe" in c.get('name', '').lower() or "pepe" in c.get('symbol', '').lower()]
                logger.info(f"Direct search for PEPE in all coins: {pepe_coins}")
            
            # Limit to top 3 matches to avoid overwhelming the response
            for match in used_matches[:3]:
                coin = match['coin']
                term = match['term']
                
                name = coin.get('name', 'Unknown')
                symbol = coin.get('symbol', '').upper()
                price = coin.get('current_price', 'unavailable')
                market_cap = coin.get('market_cap', 'unavailable')
                rank = coin.get('market_cap_rank', 'unavailable')
                price_change_24h = coin.get('price_change_percentage_24h', 'unavailable')
                
                response += f"\n{name} ({symbol}) Data:\n"
                response += f"Current Price: ${price}\n"
                if market_cap != 'unavailable':
                    response += f"Market Cap: ${market_cap:,}\n"
                else:
                    response += f"Market Cap: unavailable\n"
                    
                response += f"Market Cap Rank: #{rank}\n"
                
                if price_change_24h != 'unavailable':
                    direction = "⬆️" if price_change_24h > 0 else "⬇️"
                    response += f"24h Change: {direction} {abs(price_change_24h):.2f}%\n"
                
                logger.info(f"Added {name} ({symbol}) data to response")
        else:
            # No matches found
            query_string = ", ".join(coin_query_terms)
            response += f"\nCOIN NOT FOUND:\nThe cryptocurrency you asked about (search terms: {query_string}) "
            response += "was not found in the market data. Please verify the cryptocurrency symbol or name "
            response += "and try again. The system has data for the top 500 cryptocurrencies by market cap.\n"
            logger.info(f"No matches found for query terms: {coin_query_terms}")
        
        # Now let's add relevant news if available in context
        if 'context' in locals() and hasattr(context, 'news'):
            news_data = context.news
            
            # Collect all news items across all categories
            all_news_items = []
            
            # Collect all news titles
            if hasattr(news_data, 'crypto') and isinstance(news_data.crypto, list):
                all_news_items.extend(news_data.crypto)
                
            if hasattr(news_data, 'macro'):
                macro_data = news_data.macro
                if isinstance(macro_data, dict):
                    for category, items in macro_data.items():
                        if isinstance(items, list):
                            all_news_items.extend(items)
                elif isinstance(macro_data, list):
                    all_news_items.extend(macro_data)
                    
            if hasattr(news_data, 'reddit') and isinstance(news_data.reddit, list):
                all_news_items.extend(news_data.reddit)
            
            # Find relevant news that match key terms in the query
            relevant_news = []
            for item in all_news_items:
                if isinstance(item, dict) and "title" in item:
                    title_lower = item.get("title", "").lower()
                    # Check if any query term appears in the title
                    matches_count = sum(1 for term in query_terms if term in title_lower)
                    if matches_count > 0:
                        # Add a relevance score and a unique identifier
                        relevant_news.append((matches_count, item))
            
            # Sort by relevance score (most relevant first)
            relevant_news.sort(key=lambda x: x[0], reverse=True)
            
            # Add relevant news if any found
            if relevant_news:
                response += "\nRELEVANT NEWS BASED ON YOUR QUERY:\n"
                for score, item in relevant_news[:5]:  # Show top 5 most relevant
                    title = item.get("title", "N/A")
                    source = item.get("source", "Unknown source")
                    url = item.get("url", "")
                    response += f"- {title} (Source: {source})\n"
                    if url:
                        response += f"  URL: {url}\n"
                    response += "\n"
        
        # Add the user's message at the end
        response += f"\n=== USER QUESTION ===\n{message}\n\n"
        
        return response
    else:
        logger.warning("No market data found to process")
        return "No market data found to process"

@router.post("/analyze", response_model=Dict[str, Any])
async def analyze_content(request: AIAnalysisRequest):
    """
    Analyze content using AI
    """
    try:
        analysis_type = request.analysis_type.lower()
        
        if analysis_type == "sentiment":
            result = await analyze_sentiment(request)
            return {"analysis_type": "sentiment", "result": result}
        elif analysis_type == "prediction":
            result = await predict_market(request)
            return {"analysis_type": "prediction", "result": result}
        elif analysis_type == "insight":
            result = await generate_insight(request)
            return {"analysis_type": "insight", "result": result}
        elif analysis_type == "recommendation":
            result = await generate_recommendation(request)
            return {"analysis_type": "recommendation", "result": result}
        else:
            raise HTTPException(status_code=400, detail=f"Unsupported analysis type: {analysis_type}")
    
    except Exception as e:
        logger.error(f"Error analyzing content: {e}")
        raise HTTPException(status_code=500, detail=f"Error analyzing content: {str(e)}")

@router.get("/sentiment/{symbol}", response_model=SentimentAnalysis)
async def get_sentiment(
    symbol: str = Path(..., description="Cryptocurrency symbol"),
    time_period: str = Query("24h", description="Time period (24h, 7d, 30d)")
):
    """
    Get sentiment analysis for a specific cryptocurrency
    """
    try:
        symbol = symbol.upper()
        
        # Generate mock sentiment data
        sentiment_score = random.uniform(-1.0, 1.0)
        
        if sentiment_score > 0.3:
            sentiment_label = "POSITIVE"
        elif sentiment_score < -0.3:
            sentiment_label = "NEGATIVE"
        else:
            sentiment_label = "NEUTRAL"
        
        sources_analyzed = random.randint(50, 500)
        confidence = random.uniform(0.7, 0.95)
        
        return SentimentAnalysis(
            symbol=symbol,
            sentiment_score=sentiment_score,
            sentiment_label=sentiment_label,
            confidence=confidence,
            sources_analyzed=sources_analyzed,
            time_period=time_period,
            analyzed_at=datetime.now()
        )
    
    except Exception as e:
        logger.error(f"Error fetching sentiment for {symbol}: {e}")
        raise HTTPException(status_code=500, detail=f"Error fetching sentiment: {str(e)}")

async def analyze_sentiment(request: AIAnalysisRequest) -> SentimentAnalysis:
    """
    Analyze sentiment of provided content
    """
    content_type = request.content_type.lower()
    
    if content_type == "text":
        text = request.content
        
        # Generate mock sentiment data for the text
        sentiment_score = random.uniform(-1.0, 1.0)
        
        if sentiment_score > 0.3:
            sentiment_label = "POSITIVE"
        elif sentiment_score < -0.3:
            sentiment_label = "NEGATIVE"
        else:
            sentiment_label = "NEUTRAL"
        
        confidence = random.uniform(0.6, 0.9)
        
        return SentimentAnalysis(
            text=text[:100] + "..." if len(text) > 100 else text,
            sentiment_score=sentiment_score,
            sentiment_label=sentiment_label,
            confidence=confidence,
            analyzed_at=datetime.now()
        )
    else:
        raise HTTPException(status_code=400, detail=f"Unsupported content type for sentiment analysis: {content_type}")

@router.get("/predict/{symbol}", response_model=MarketPrediction)
async def get_prediction(
    symbol: str = Path(..., description="Cryptocurrency symbol"),
    time_frame: str = Query("24h", description="Time frame (24h, 7d, 30d)")
):
    """
    Get price prediction for a specific cryptocurrency
    """
    try:
        symbol = symbol.upper()
        
        # Load current price data
        market_data_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))), "market_data.json")
        
        try:
            with open(market_data_path, 'r') as f:
                market_data = json.load(f)
            
            # Find the specific cryptocurrency
            price_data = next(
                (p for p in market_data.get("prices", []) if p.get("symbol", "").upper() == symbol),
                None
            )
            
            if not price_data:
                raise HTTPException(status_code=404, detail=f"Price data for {symbol} not found")
            
            current_price = price_data.get("priceUsd", 1000.0)
        except Exception:
            # Fallback to dummy data if file can't be read
            current_price = 1000.0 if symbol == "BTC" else 100.0
        
        # Generate prediction data
        if time_frame == "24h":
            # Generate prediction with smaller variation for short term
            prediction_date = datetime.now() + timedelta(days=1)
            prediction_price = current_price * (1 + random.uniform(-0.05, 0.08))
            confidence = random.uniform(0.7, 0.9)
        elif time_frame == "7d":
            # Medium term prediction
            prediction_date = datetime.now() + timedelta(days=7)
            prediction_price = current_price * (1 + random.uniform(-0.15, 0.2))
            confidence = random.uniform(0.6, 0.8)
        else:  # 30d
            # Longer term has more variation and lower confidence
            prediction_date = datetime.now() + timedelta(days=30)
            prediction_price = current_price * (1 + random.uniform(-0.3, 0.4))
            confidence = random.uniform(0.5, 0.7)
        
        features_used = [
            "price_history",
            "volume_trends",
            "market_sentiment",
            "technical_indicators",
            "social_media_data"
        ]
        
        return MarketPrediction(
            symbol=symbol,
            time_frame=time_frame,
            prediction_price=prediction_price,
            confidence=confidence,
            prediction_date=prediction_date,
            generated_at=datetime.now(),
            model_version="v1.2.3",
            features_used=features_used
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error generating prediction for {symbol}: {e}")
        raise HTTPException(status_code=500, detail=f"Error generating prediction: {str(e)}")

async def predict_market(request: AIAnalysisRequest) -> MarketPrediction:
    """
    Generate market prediction based on request
    """
    content_type = request.content_type.lower()
    
    if content_type == "market_data":
        # Extract symbol and time frame from content
        content = request.content
        symbol = content.get("symbol", "BTC").upper()
        time_frame = content.get("time_frame", "24h")
        
        # Generate prediction based on the same logic as the GET endpoint
        return await get_prediction(symbol, time_frame)
    else:
        raise HTTPException(status_code=400, detail=f"Unsupported content type for market prediction: {content_type}")

@router.get("/insights", response_model=List[MarketInsight])
async def get_insights(
    symbols: Optional[str] = Query(None, description="Comma-separated list of cryptocurrency symbols"),
    categories: Optional[str] = Query(None, description="Comma-separated categories (technical, fundamental, sentiment, news)"),
    limit: int = Query(5, description="Number of insights to return")
):
    """
    Get AI-generated market insights
    """
    try:
        # Parse parameters
        symbol_list = []
        if symbols:
            symbol_list = [s.strip().upper() for s in symbols.split(",")]
        
        category_list = []
        if categories:
            category_list = [c.strip().lower() for c in categories.split(",")]
        
        # Default symbols for when none are specified
        if not symbol_list:
            symbol_list = ["BTC", "ETH", "SOL", "DOT", "LINK", "ADA"]
        
        # Default categories when none are specified
        if not category_list:
            category_list = ["technical", "fundamental", "sentiment", "news", "on-chain"]
        
        # Generate mock insights
        insights = []
        
        insight_titles = [
            "Accumulation phase detected",
            "Bullish divergence forming",
            "Increased institutional interest",
            "Bearish sentiment reaching extreme levels",
            "Strong resistance level testing",
            "Major protocol upgrade approaching",
            "Exchange flows indicate selling pressure",
            "Whale activity intensifying",
            "Market sentiment turning positive",
            "Technical breakout imminent"
        ]
        
        for _ in range(min(limit, 10)):
            # Randomly select symbols and categories for this insight
            insight_symbols = random.sample(symbol_list, min(random.randint(1, 3), len(symbol_list)))
            insight_categories = random.sample(category_list, min(random.randint(1, 3), len(category_list)))
            
            # Generate mock content based on selected symbols and categories
            symbol_text = ", ".join(insight_symbols)
            category_text = " and ".join(insight_categories)
            title = random.choice(insight_titles)
            content = f"Analysis of {symbol_text} shows significant {category_text} developments. "
            content += "Recent data indicates changing market conditions that suggest potential price movement. "
            content += "Key metrics to watch include volume trends, social sentiment, and technical indicator convergence."
            
            # Generate random sources
            sources = []
            possible_sources = ["TradingView", "CryptoQuant", "Glassnode", "Santiment", "CoinMetrics", "Messari", "News Analysis"]
            num_sources = random.randint(1, 4)
            sources = random.sample(possible_sources, num_sources)
            
            insights.append(MarketInsight(
                id=f"insight-{uuid.uuid4()}",
                title=f"{symbol_text} {title}",
                content=content,
                symbols=insight_symbols,
                categories=insight_categories,
                generated_at=datetime.now() - timedelta(hours=random.randint(0, 48)),
                confidence=random.uniform(0.6, 0.95),
                sources=sources
            ))
        
        # Sort by most recent
        insights.sort(key=lambda x: x.generated_at, reverse=True)
        
        return insights
    
    except Exception as e:
        logger.error(f"Error generating market insights: {e}")
        raise HTTPException(status_code=500, detail=f"Error generating market insights: {str(e)}")

async def generate_insight(request: AIAnalysisRequest) -> MarketInsight:
    """
    Generate market insight based on request
    """
    content_type = request.content_type.lower()
    
    if content_type in ["market_data", "news", "portfolio"]:
        content = request.content
        
        # Extract symbols from content
        symbols = []
        if isinstance(content, dict) and "symbols" in content:
            symbols = [s.upper() for s in content.get("symbols", [])]
        elif isinstance(content, dict) and "symbol" in content:
            symbols = [content.get("symbol", "BTC").upper()]
        else:
            symbols = ["BTC", "ETH"]  # Default symbols
        
        # Generate a mock insight
        insight_titles = [
            "Accumulation phase detected",
            "Bullish divergence forming",
            "Increased institutional interest",
            "Market cycle analysis"
        ]
        
        title = random.choice(insight_titles)
        symbol_text = ", ".join(symbols)
        
        # Generate mock content
        content_text = f"Analysis of {symbol_text} shows interesting market developments. "
        content_text += "Recent data indicates changing market conditions that suggest potential price movement. "
        content_text += "Key metrics to watch include volume trends, social sentiment, and technical indicator convergence."
        
        return MarketInsight(
            id=f"insight-{uuid.uuid4()}",
            title=f"{symbol_text} {title}",
            content=content_text,
            symbols=symbols,
            categories=["technical", "sentiment"],
            generated_at=datetime.now(),
            confidence=random.uniform(0.7, 0.9),
            sources=["TradingView", "CryptoQuant", "News Analysis"]
        )
    else:
        raise HTTPException(status_code=400, detail=f"Unsupported content type for market insight: {content_type}")

@router.get("/recommendations", response_model=PortfolioRecommendation)
async def get_recommendations(
    risk_profile: str = Query("moderate", description="Risk profile (conservative, moderate, aggressive)"),
    user_id: str = Query("user123", description="User ID")
):
    """
    Get AI-generated portfolio recommendations
    """
    try:
        # Validate risk profile
        if risk_profile.lower() not in ["conservative", "moderate", "aggressive"]:
            risk_profile = "moderate"
        
        # Generate recommendations based on risk profile
        recommendations = []
        
        if risk_profile.lower() == "conservative":
            recommendations = [
                {"symbol": "BTC", "name": "Bitcoin", "allocation": 30.0},
                {"symbol": "ETH", "name": "Ethereum", "allocation": 20.0},
                {"symbol": "USDC", "name": "USD Coin", "allocation": 40.0},
                {"symbol": "SOL", "name": "Solana", "allocation": 5.0},
                {"symbol": "BNB", "name": "Binance Coin", "allocation": 5.0}
            ]
            expected_return = 15.5
            rationale = "This conservative allocation prioritizes stability with a high stablecoin allocation while maintaining exposure to established cryptocurrencies."
            
        elif risk_profile.lower() == "moderate":
            recommendations = [
                {"symbol": "BTC", "name": "Bitcoin", "allocation": 35.0},
                {"symbol": "ETH", "name": "Ethereum", "allocation": 30.0},
                {"symbol": "SOL", "name": "Solana", "allocation": 15.0},
                {"symbol": "DOT", "name": "Polkadot", "allocation": 10.0},
                {"symbol": "USDC", "name": "USD Coin", "allocation": 10.0}
            ]
            expected_return = 25.5
            rationale = "This balanced allocation provides growth potential with a moderate risk level, focusing on established layer 1 protocols and maintaining some stablecoin reserves."
            
        else:  # aggressive
            recommendations = [
                {"symbol": "BTC", "name": "Bitcoin", "allocation": 30.0},
                {"symbol": "ETH", "name": "Ethereum", "allocation": 25.0},
                {"symbol": "SOL", "name": "Solana", "allocation": 15.0},
                {"symbol": "AVAX", "name": "Avalanche", "allocation": 10.0},
                {"symbol": "DOT", "name": "Polkadot", "allocation": 10.0},
                {"symbol": "LINK", "name": "Chainlink", "allocation": 5.0},
                {"symbol": "MATIC", "name": "Polygon", "allocation": 5.0}
            ]
            expected_return = 35.8
            rationale = "This aggressive allocation maximizes growth potential with a focus on high-performance blockchain protocols and essential infrastructure, suitable for investors comfortable with higher volatility."
        
        return PortfolioRecommendation(
            user_id=user_id,
            recommendations=recommendations,
            risk_profile=risk_profile.lower(),
            expected_return=expected_return,
            generated_at=datetime.now(),
            rationale=rationale
        )
    
    except Exception as e:
        logger.error(f"Error generating portfolio recommendations: {e}")
        raise HTTPException(status_code=500, detail=f"Error generating portfolio recommendations: {str(e)}")

async def generate_recommendation(request: AIAnalysisRequest) -> PortfolioRecommendation:
    """
    Generate portfolio recommendation based on request
    """
    content_type = request.content_type.lower()
    
    if content_type == "portfolio":
        content = request.content
        
        # Extract parameters from content
        risk_profile = content.get("risk_profile", "moderate").lower()
        user_id = content.get("user_id", "user123")
        
        # Use the same logic as the GET endpoint
        return await get_recommendations(risk_profile, user_id)
    else:
        raise HTTPException(status_code=400, detail=f"Unsupported content type for portfolio recommendation: {content_type}")

@router.get("/health", response_model=Dict[str, Any])
async def ai_health_check():
    """
    Check if the AI service is properly configured and connected to OpenAI.
    """
    try:
        # Check if OpenAI API key is set
        api_key_set = openai_service.api_key is not None and len(openai_service.api_key) > 0
        
        # Check if OpenAI client is initialized
        client_initialized = openai_service.client is not None and openai_service.async_client is not None
        
        # Return health status
        return {
            "status": "ok" if api_key_set and client_initialized else "error",
            "api_key_configured": api_key_set,
            "client_initialized": client_initialized,
            "timestamp": datetime.now().isoformat(),
            "api_base": os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1"),
            "models_available": ["gpt-4-turbo-preview", "gpt-3.5-turbo"],
            "port": os.getenv("PORT", "8000")
        }
    except Exception as e:
        logger.error(f"Error checking AI health: {str(e)}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@router.post("/query")
async def process_query(request: dict = Body(...)):
    """
    Process a query from the frontend and return AI response
    This endpoint is designed to be compatible with the frontend's expectations
    """
    try:
        logger.info(f"Received query request: {request}")
        
        # Extract the query from request
        query = request.get("query", "")
        
        if not query.strip():
            return {
                "message": "Please provide a valid query",
                "status": "error",
                "error_type": "validation_error"
            }
            
        # Classify the intent
        intent_type, confidence = intent_classifier.classify(query)
        logger.info(f"Classified intent: {intent_type.name} with confidence {confidence:.2f}")
        
        # Import the market service here to avoid circular imports
        from app.services.market.market_data_service import MarketDataService
        
        # Get real market data
        market_service = MarketDataService()
        market_data = await market_service.get_market_data()
        
        # Get portfolio data 
        portfolio_file = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))), "data", "portfolio", "user_portfolio_holdings.json")
        portfolio_data = []
        
        try:
            if os.path.exists(portfolio_file):
                with open(portfolio_file, 'r') as f:
                    portfolio_data = json.load(f)
        except Exception as e:
            logger.error(f"Error loading portfolio data: {e}")
        
        # Initialize response message
        response_message = ""
        
        if intent_type == IntentType.MARKET_PRICE:
            # Handle price queries
            coin_symbol = None
            
            # Check for common coins in the query
            query_lower = query.lower()
            if "bitcoin" in query_lower or "btc" in query_lower:
                coin_symbol = "BTC"
            elif "ethereum" in query_lower or "eth" in query_lower:
                coin_symbol = "ETH"
            elif "solana" in query_lower or "sol" in query_lower:
                coin_symbol = "SOL"
            elif "avalanche" in query_lower or "avax" in query_lower:
                coin_symbol = "AVAX"
            
            if coin_symbol and "prices" in market_data:
                # Find the coin in the market data
                coin_data = next((coin for coin in market_data["prices"] if coin["symbol"].upper() == coin_symbol), None)
                
                if coin_data:
                    # Format the response with real data
                    name = coin_data.get("name", coin_symbol)
                    price = coin_data.get("priceUsd", 0)
                    change = coin_data.get("change24h", 0)
                    change_direction = "up" if change > 0 else "down"
                    response_message = f"{name} ({coin_symbol}) is currently trading at ${price:,.2f} USD, {change_direction} {abs(change):.1f}% in the last 24 hours."
                else:
                    response_message = f"I couldn't find current market data for {coin_symbol}. Please try another cryptocurrency."
            else:
                # Get overview data if no specific coin was mentioned
                if "overview" in market_data:
                    overview = market_data["overview"]
                    btc_dominance = overview.get("btcDominance", 0)
                    total_market_cap = overview.get("totalMarketCapUsd", 0)
                    response_message = f"The total cryptocurrency market cap is currently ${total_market_cap:,.0f} USD with Bitcoin dominance at {btc_dominance:.2f}%."
                else:
                    response_message = "I'm having trouble retrieving current market data. Please try again later."
        
        elif intent_type == IntentType.PORTFOLIO_ANALYSIS:
            # Calculate portfolio value from real data
            if portfolio_data:
                total_value = 0
                holdings_text = []
                
                for asset in portfolio_data:
                    symbol = asset.get("symbol", "").upper()
                    quantity = asset.get("quantity", 0)
                    
                    # Find current price in market data
                    price = 0
                    if "prices" in market_data:
                        coin_data = next((coin for coin in market_data["prices"] if coin["symbol"].upper() == symbol), None)
                        if coin_data:
                            price = coin_data.get("priceUsd", 0)
                    
                    # Use price from asset data if not found in market data
                    if price == 0:
                        price = asset.get("price_usd", 0)
                    
                    value = quantity * price
                    total_value += value
                    
                    holdings_text.append(f"{asset.get('name', symbol)} ({quantity} {symbol})")
                
                if holdings_text:
                    assets_text = ", ".join(holdings_text)
                    response_message = f"Your portfolio currently contains {assets_text} with a total value of ${total_value:,.2f} USD."
                else:
                    response_message = "Your portfolio appears to be empty. You can add assets through the Portfolio section."
            else:
                response_message = "I couldn't find your portfolio data. You can add assets through the Portfolio section."
        
        elif intent_type == IntentType.NEWS:
            # Get real news data
            from app.services.news import crypto_news_service
            
            try:
                news_items = crypto_news_service.get_cached_news(limit=3)
                
                if news_items:
                    response_message = "Here are the latest crypto news headlines:\n\n"
                    for item in news_items:
                        title = item.get("title", "")
                        source = item.get("source", "")
                        response_message += f"• {title} (Source: {source})\n"
                else:
                    response_message = "I'm currently unable to retrieve the latest crypto news. Please try again later."
            except Exception as news_error:
                logger.error(f"Error fetching news: {news_error}")
                response_message = "I'm currently unable to retrieve the latest crypto news. Please try again later."
        
        else:
            # General market info for other intents
            if "overview" in market_data and "prices" in market_data:
                overview = market_data["overview"]
                btc_dominance = overview.get("btcDominance", 0)
                
                # Get the top 3 coins by market cap
                top_coins = sorted(market_data["prices"], key=lambda x: x.get("marketCap", 0), reverse=True)[:3]
                
                if top_coins:
                    coins_text = ", ".join([f"{coin.get('name', '')} (${coin.get('priceUsd', 0):,.2f})" for coin in top_coins])
                    response_message = f"The crypto market currently shows Bitcoin dominance at {btc_dominance:.2f}%. Top cryptocurrencies: {coins_text}."
                else:
                    response_message = f"The crypto market currently shows Bitcoin dominance at {btc_dominance:.2f}%."
            else:
                response_message = "I'm currently retrieving the latest market data for your query. Please try again in a moment."
        
        # Format the response to match what the frontend expects
        formatted_response = {
            "message": response_message,
            "status": "success",
            "intent": intent_type.name,
            "confidence": confidence
        }
        
        logger.info(f"Query processed successfully with intent: {intent_type.name}")
        return formatted_response
    
    except Exception as e:
        logger.error(f"Error processing query: {e}")
        return {
            "message": f"An error occurred while processing your query: {str(e)}",
            "status": "error",
            "error_type": "processing_error",
            "error_details": str(e)
        } 